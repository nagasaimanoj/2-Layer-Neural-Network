{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2 Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## needed imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import (\n",
    "    array, # to make matrix operations easy\n",
    "    dot, # matrix multiplication func\n",
    "    exp # for sigmoid func\n",
    ")\n",
    "from numpy.random import (\n",
    "    random, # for random number generation\n",
    "    seed # for getting random number each time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Class for Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronLayer():\n",
    "    \"\"\" \n",
    "        Each layer contains many neurons and each neuron can accept any inputs.\n",
    "        But each neuron can produce only 1 output, which will be fed into next layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        number_of_neurons, # no.of neurons per each layer\n",
    "        number_of_inputs_per_neuron # no.of inputs each neuron should work with\n",
    "    ):\n",
    "        # taking random weights for each neuron in current layer (weights per neuron * no of neurons)\n",
    "        self.synaptic_weights = 2 * random((number_of_inputs_per_neuron, number_of_neurons)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Class for Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \"\"\"\n",
    "        The complete network, with multiple layers configured\n",
    "        This takes inputs to the 1st layer and gives output form the last layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        layer1, # Starting point of Neural Network. entry point for data\n",
    "        layer2 # Ending point of Neural Network. this returns predictions\n",
    "    ):\n",
    "        self.layer1 = layer1\n",
    "        self.layer2 = layer2\n",
    "\n",
    "    def __sigmoid(self, x):\n",
    "        # sigmoid func, used as a Perceptron\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        # derivative of sigmoid func, used to alter weights\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(\n",
    "        self, \n",
    "        training_set_inputs, # independent variables (x)\n",
    "        training_set_outputs, # dependent variables (y)\n",
    "        number_of_training_iterations # iterations for gradiant descent\n",
    "    ):\n",
    "        for _ in range(number_of_training_iterations):\n",
    "\n",
    "            # output from both layers are calculated. ideally, layer 2's output should match with (y)\n",
    "            output_from_layer_1, output_from_layer_2 = self.predict(training_set_inputs)\n",
    "\n",
    "            # deviation from (y) to layer 2 is calculated to alter weights of layer 2\n",
    "            layer2_error = training_set_outputs - output_from_layer_2\n",
    "            layer2_delta = layer2_error * self.__sigmoid_derivative(output_from_layer_2)\n",
    "\n",
    "            # deviation from new layer 2 to layer 1 is calculated to alter weights of layer 1\n",
    "            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n",
    "            layer1_delta = layer1_error * self.__sigmoid_derivative(output_from_layer_1)\n",
    "\n",
    "            # altering each layer slightly at a time, based on amount of deviation each had\n",
    "            layer1_adjustment = training_set_inputs.T.dot(layer1_delta)\n",
    "            layer2_adjustment = output_from_layer_1.T.dot(layer2_delta)\n",
    "\n",
    "            self.layer1.synaptic_weights += layer1_adjustment\n",
    "            self.layer2.synaptic_weights += layer2_adjustment\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "            This calculates sigmoid at layer 1 & gives its results to layer 2 and returns its results\n",
    "        \"\"\"\n",
    "\n",
    "        # input variables are multiplied with weights & calculated sigmoid\n",
    "        output_from_layer1 = self.__sigmoid(dot(inputs, self.layer1.synaptic_weights))\n",
    "\n",
    "        # layer 1 output is multiplied with layer 2 weights and calculated sigmoid for them as well\n",
    "        output_from_layer2 = self.__sigmoid(dot(output_from_layer1, self.layer2.synaptic_weights))\n",
    "\n",
    "        # returning both layer's output to optimize weights at each layer\n",
    "        return output_from_layer1, output_from_layer2\n",
    "\n",
    "    def print_weights(self):\n",
    "        \"\"\" prints weights of both layers \"\"\"\n",
    "\n",
    "        print(\"Layer 1 (4 neurons, each with 3 inputs):\")\n",
    "        print(self.layer1.synaptic_weights)\n",
    "\n",
    "        print(\"Layer 2 (1 neuron, with 4 inputs):\")\n",
    "        print(self.layer2.synaptic_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Usage of Above Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Stage 1) Random starting synaptic weights:\nLayer 1 (4 neurons, each with 3 inputs):\n[[-0.16595599  0.44064899 -0.99977125 -0.39533485]\n [-0.70648822 -0.81532281 -0.62747958 -0.30887855]\n [-0.20646505  0.07763347 -0.16161097  0.370439  ]]\nLayer 2 (1 neuron, with 4 inputs):\n[[-0.5910955 ]\n [ 0.75623487]\n [-0.94522481]\n [ 0.34093502]]\nStage 2) New synaptic weights after training: \nLayer 1 (4 neurons, each with 3 inputs):\n[[ 0.3122465   4.57704063 -6.15329916 -8.75834924]\n [ 0.19676933 -8.74975548 -6.1638187   4.40720501]\n [-0.03327074 -0.58272995  0.08319184 -0.39787635]]\nLayer 2 (1 neuron, with 4 inputs):\n[[ -8.18850925]\n [ 10.13210706]\n [-21.33532796]\n [  9.90935111]]\nStage 3) Considering a new situation [1, 1, 0] -> ?: \n[0.0078876]\n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # seeding random variable to get same random values each time\n",
    "    seed(1)\n",
    "\n",
    "    # defining layers with no.of neurons and their no.of inputs\n",
    "    layer1 = NeuronLayer(number_of_neurons=4, number_of_inputs_per_neuron=3)\n",
    "    layer2 = NeuronLayer(number_of_neurons=1, number_of_inputs_per_neuron=4)\n",
    "\n",
    "    # defining neural network with defined layers\n",
    "    neural_network = NeuralNetwork(layer1=layer1, layer2=layer2)\n",
    "\n",
    "    # printing initial weights for each layer\n",
    "    print(\"Stage 1) Random starting synaptic weights:\")\n",
    "    neural_network.print_weights()\n",
    "\n",
    "    # independent variables (x)\n",
    "    training_set_inputs = array([[0, 0, 1],\n",
    "                                 [0, 1, 1],\n",
    "                                 [1, 0, 1],\n",
    "                                 [0, 1, 0],\n",
    "                                 [1, 0, 0],\n",
    "                                 [1, 1, 1],\n",
    "                                 [0, 0, 0]])\n",
    "    # dependent variables (y)\n",
    "    training_set_outputs = array([[0],\n",
    "                                  [1],\n",
    "                                  [1],\n",
    "                                  [1],\n",
    "                                  [1],\n",
    "                                  [0],\n",
    "                                  [0]])\n",
    "\n",
    "    # training defined neural network with (x) -> (Y) for 60000 iterations\n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 60000)\n",
    "\n",
    "    # printing final weights for each layer after training\n",
    "    print(\"Stage 2) New synaptic weights after training: \")\n",
    "    neural_network.print_weights()\n",
    "\n",
    "    # printing predictions for untrained parameters\n",
    "    print(\"Stage 3) Considering a new situation [1, 1, 0] -> ?: \")\n",
    "    hidden_state, output = neural_network.predict(array([1, 1, 0]))\n",
    "\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}